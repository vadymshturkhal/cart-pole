# üìù TODOs for CartPole N-step Q-learning Repo

- [ ] Compare NStepDQN with NStepDDQN;
- [ ] Test menu choosing models for correctness;
- [ ] Draggable indicator;
- [ ] Do it optional to print to console using menu training variant;
- [ ] Change config from menu;
- [ ] Add box with plot rewards after training choice;
- [ ] Remain only off and human rendering modes;
- [ ] Add button for choosing training environment;
- [ ] Add quantity of episodes for Testing models;
- [ ] Add pause/continue buttons for Agent in training mode;
- [ ] Stop Training button must clear the plot;
- [ ] Add Average and Average 100 rewards section to description of a trained model;
- [ ] Update README.md;
- [ ] Add Model management panel;
- [ ] More visualizations like epsilon decay, loss or last N episode returns histogram;
- [ ] Add a log window to capture status messages and scroll through training history (episode rewards, averages);
- [ ] Decouple hyperparameters from launcher;
- [ ] Add Create Agent section;
- [ ] Stop rendering after pressing Back to Main button;
- [ ] Add logger to Testing section;
- [ ] Make log window with all info from Agent when training;
- [ ] Grouping related controls into collapsible panels;
- [ ] Add feature to choose already trained agent for further training;
- [ ] Add feature to save GIF in Testing section;
- [ ] Create ModelInfoWidget;
- [ ] Create TestingWorker;
- [ ] Create Experiments section with Barto, Sutton, and Anderson (1983) Cart Pole;
- [ ] Set min training episodes for training;
- [ ] Planning for resume/continue training (hyperparam overrides);
- [ ] Add unit testing;
- [ ] Add Specific section with description to agent choosing in Training section;
- [ ] Add continuous environment;
- [ ] Hide discrete agents for continuous environments and vice versa;
- [ ] Add target network update	every N steps to AgentDialog in Training section;
- [ ] Add 'Load hyperparams from config' button for agent in Training section;
- [ ] Zoom in for plots;
- [ ] Selectable params in Testing section;
- [ ] Zero must lined at Reward Plot;
- [ ] Adaptive learning rate as option;
- [ ] Integrate Stable Baselines3 agents;
- [ ] Testing Section: Make status line smarter ‚Äî e.g., show step count, FPS, or a small green ‚Äúlive‚Äù dot while testing runs;
- [ ] Add Episodes quantity to Testing section;
- [ ] Add FPS to Training Logger;
- [ ] Add episode/total_episodes to Training Logger;
- [ ] Add loss to NN optimization in Training section;
- [ ] Add networks to NN optimization in Training section;
- [ ] Add speed adjustment for environment in Testing section;
- [ ] Add tab for each section in model's JSON in Testion section in model info window;
- [ ] Add Get Raw data which can get full model info JSON and provide selection of that info in place;
- [ ] Add Night Mode to GUI;
- [ ] Add Export model JSON button to Training section;
- [ ] Add Save as Default option to Agent and Environment configurations;
- [ ] Add Restore config button;
- [ ] Show rewards in Testing section console;
- [ ] Add 'From loaded model' message to all configs after loading model;
- [ ] Color low rewards with red, average with yellow and high with green;
- [ ] Add 'Export Logs' button;
- [ ] Add 'Training time' to model data;
- [ ] Add options to Agent Config for choosing epsilon decays;
- [ ] Add loss clipping to Training section NN configuration;
- [ ] Add 'Load last session' to Main Menu;
- [ ] Fix incorrect Training episodes showing after Apply;
- [ ] Move Apply/Cancel to the top of configs window;
- [ ] Add saving model during training;
- [ ] Add 'Stop episode' to Testing section during an episode:
- [ ] Add episode based ReplayBuffer;
- [ ] Plots should be scaled to stop episode, not the whole set episodes, e.g. to 80 if stop is 80 in 800 episodes training;
- [ ] Add eps_current to dqn_agent for showing current epsilon after stopping training;


## Done
- [x] Add 'Update plots every:' to Plots Panel;
- [x] Fix loss plot episodes after applying in Environment settings;
- [x] Add fixed epsilon to Epsilon Schedule;
- [x] Rename Cancel to Close in NN config;
- [x] Add epsilon to log;
- [x] Set Read-only mode to NN hidden layers after loading model;
- [x] Add Configure Environment button in Training section;
- [x] Add max_step_per_episode to Training section;
- [x] In Training section make some buttons unavailable during training;
- [x] Add CUDA to Training section;
- [x] In autosave save model's related data with model's name;
- [x] Save Loss plot after training;
- [x] Save Reward plot, reward.csv, model.pth and json data after training;
- [x] Sort models in Testing section;
- [x] Add some activations to hidden layer;
- [x] In Testing section maked some buttons unavailable;
- [x] Add detailed description to agent after training, including optimizer, loss, nn layers;
- [x] Add date to trained model's data;
- [x] Add DDPG (Deep Deterministic Policy Gradient) agent for continuous environments;
- [x] Add setting NN button;
- [x] Add loss plot;
- [x] Get rid of train_menu;
- [x] After choosing agent there must be info about its parameters;
- [x] Refactor reward_plot;
- [x] Contain reaquired hyperparameters in agent's class;
- [x] Update ase_ace agent to use torch;
- [x] Update ase_ace agent to use BaseAgent's API;
- [x] Update nstep_ddqn agent to use BaseAgent's API;
- [x] Standardise Agent's API;
- [x] Variables Dialog in Training section when choosing agent, must be specific for choosen agent;
- [x] Create TestSection class;
- [x] Refactor launcher.py;
- [x] Create TrainingSection class;
- [x] Test pre-trained model shouldn't open another window, it is better to show the test in another section instead;
- [x] Add Change resolution button with save to config;
- [x] Adjust console training;
- [x] Raise error if choose a wrong agent for training in wrong environment (solved by choosing environment from model's data);
- [x] Add Delete Agent button;
- [x] Autosave and save button for trained models;
- [x] Save trained models with particular name, descriptions;
- [x] Add environment to saved model;
- [x] Start decoupling environment from GUI;
- [x] Add trained episodes/all episodes to model's data;
- [x] Add starting menu;
- [x] Separate console and menu variants;
- [x] Add sidebar to menu variant;
- [x] Add scrolling to sidebar;
- [x] Training menu doesn't close immediately after training;
- [x] Update README to use menu or console training variants;
- [x] Plotting training curve in training window;
- [x] Global average in training window;
- [x] Decompose train_menu.py
- [x] Add feature to test model after training in menu mode;
- [x] More professional GUI;
- [x] Resolution to config;
- [x] Fixed closing Cart Pole human mode window;
- [x] Parameters button in menu;
- [x] Update agent's api for using hyperparameters from menu;
- [x] Decomposed train_qt_menu.py
- [x] Start button bug when pushing couple of times;
- [x] Add stop button;
- [x] Add global average;
- [x] Adjusting parameters in starting menu;
- [x] Render mode human works in Qt menu;
- [x] Save trained models with info about hyperparameters;
- [x] Load trained models in additional window with the description of a model;
- [x] Reorganize GUI test/train buttons and showing model's info;
- [x] Save info about agent's hyperparamaters with model;
- [x] Add feature to train or test trained agent to starting menu;
